#!/usr/bin/python

#simple script to check for disallow in robots.txt
#simple custom exception to throw if a Disallow is found

class DisallowPresent(Exception):
	def __init__(self, path):
		self.disallowed_path = path
	def __str__(self):
		return repr(self.disallowed_path)

import urllib2

secTube = urllib2.urlopen('http://www.bbc.co.uk/robots.txt')

for line in secTube.readLines():
	try:
		if line.lower().find('disallow') != -1 :
			print line.strip()
			raise DisallowPresent(line.split(':')[1].strip())

	except DisallowPresent as ex :
		print "Exception occured for path : " +ex.disallowed_path
